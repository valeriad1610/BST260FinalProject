---
title: "Final Project Code"
author: "Valeria Duran"
date: "2022-12-12"
output: html_document
---

---
title: "#MeToo: Hatefulness of Twitter Users"
author: "Valeria Duran, BST260 Final Project"
date: "2022-12-03"
output:
  pdf_document: default
  html_document: default
---

## Introduction 

This dataset, ‘Hatred on Twitter During MeToo Movement’, pulled 807,174 MeToo-related tweets from September 28, 2018 to February 16, 2019. The MeToo Movement calls attention to the frequency at which, primarily women and girls, experience sexual assault and harassment. This dataset contains information on ten indicators: a unique ID for each tweet, tweet text, timestamp of tweet, like count, retweet count, location mentioned by user wile tweeting, follower count, following count, total user tweet count, and whether tweet belongs to hatred or non-hated (binary variable). The spread of hateful messaging on twitter is harmful, especially in the context of the MeToo Movement, which is meant to amplify the voices and experiences of survivors of sexual assault. Hateful messaging on twitter diluted the MeToo campaign (Lingdren, 2019). Thus, it is important to understand what types of accounts and what types of tweets sentiments spread hateful messaging. This project explores the question: how do account attributes (i.e., following count, follower count) and sentiment of tweets predict the hatefulness (binary yes/no) of a user.  

## Exploratory Analysis 

As seen in **Figures** **1** and **2**, the distributions of follower and following count were heavily skewed to the right, thus outliers were removed. To further explore account attributes, the correlation between follower count and following count per user was calculated; as seen in **Fig. 3**, these two attributes demonstrate a slight positive correlation, with r= 0.57 and p>2.2e-16. Because there is no evident strong correlation between following and follower counts, we will proceed with exploring follower and following counts. As seen in **Figures** **4** and **5**, there is a scattered trend between account attributes and proportion of hateful tweets per user. However, there are many users which tweet either entirely hateful or entirely non-hateful tweets (proportion = 1, 0, respectively). There is a sizable concentration of users who tweeted a proportion 0.1-0.3 hateful tweets and another sizable concentration of users that have never tweeted hatefully. Thus, we proceed by dichotomizing hateful accounts; a user is hateful if they have ever tweeted hatefully (proportion of hateful tweets>0). Additionally, average sentiment score tends to be lower in hateful users, as seen in **Fig. 6**. Thus, we will proceed with models which explore the impact of average sentiment, follower count, an following count on account hatefulness towards the MeToo Movement. 

## Methods 

Each user is identified and grouped by their unique combination of following count, followers count, and location. Sentiment of tweets are derived from “afinn” in the tidtytext package. An average sentiment score is assigned to each user (calculated by averaging the sentiment of words per tweet per user).  

We will explore the prediction of account hatefulness by average sentiment of users and account attributes using the caret package train function with logistic regression models and 80/20 ratio of train/test, based on a random sample of 40,000 tweets. The full predictive logistic regression model will contain 3 features: following counts, follower counts, and average sentiment scores per user. We first create predictive model 1 using only 1 feature: average sentiment of tweets per user. Subsequently, in predictive model 2 we will add follower and following counts, having 3 features in total.  We will obtain the accuracies predictive models 1 and 2 with confusion matrices. We will compare the distributions of predictive probabilities generated from the predictive models 1 and 2 using an overlayed histogram. 

As secondary analysis, we will include only users which have tweeted more than once on the MeToo movement. We conduct the two predictive logistic regression models with the same features as previously described in predictive models 1 and 2. We will obtain the accuracies of each model with confusion matrices and compare distributions of predictive probabilities generated from train models in an overlayed histogram. 

## Results 

The dataset pulled from Kaggle contained one column, ‘text’, which contained the entire text of a tweet, including links, stop words, NAs, and emojis. String processing and the tidyverse package were utilized to remove stop words, links, emojis, and NA values from the data set. Then, text mining methods in the tidytext package were utilized to expand the dataset to include one row per word, assign sentiment values, and average sentiment score grouped by user. A dichotomous variable for hateful/non-hateful user was created. Then, variables for the average sentiment scores per user and hateful user were joined with the original dataset to include account attributes needed for analysis. This data wrangling was necessary for our analysis, given our need for one data frame which included an average sentiment score per twitter user, the outcome variable (I.e., hateful/non-hateful user) and important predictive attributes (I.e., following and follower counts). The data before and after wrangling is demonstrated in Appendix: Data Wrangling

This project aims to understand how account attributes, specifically following and follower count predict the hatefulness (hateful or not hateful) of a twitter account toward the MeToo movement. To build the predictive models, we first evaluated the association between average sentiment of a tweet and the hatefulness of an account. We set a prediction rule of 0.5; this is because a 0.5 is a standard cutoff. This model generated an accuracy of 0.835, the confusion matrix of the results is seen in **Fig. 7**. The model accurately predicted all non-hateful accounts; however, it generated no prediction of hateful accounts. In fact, all probabilities generated were below 0.5, as seen in red in **Fig. 9**. Further, we added following and follower counts to the logistic regression prediction model; using the same prediction rule of 0.5, the full model generates the same accuracy and results, as seen in **Fig. 8**. **Fig. 9** compares the probability distributions for the full and partial models, which demonstrates that the full model (blue) has a slightly higher maximum probability (0.31) than that of the model which only used average sentiment as a predictor (0.28). Despite the changes in predictive probabilities in the full model, the accuracy and results of the full model remained unchanged, as seen in **Fig. 8**. 

In the secondary analysis, we excluded users which tweeted only once, this left 1153 users. This exclusion allows us to have a better estimate of the hatefulness of a user, given the outcome variable (hatefulness of user yes/no) is informed by at least two tweets. 

Using this subset of the data, we then fit a logistic regression model with average sentiment as the single predictor. With a 0.5 prediction rule, this model generated a 73% accuracy. As shown in **Fig. 10**, this model accurately predicted all non-hateful users and was unable to predict any hateful users. When following and follower counts are added to the model, the accuracy and results do not change, as seen in **Fig. 11**. However, the predictive probabilities differ between the partial (red) and full models (blue), as seen in the comparison of their distributions in **Fig. 12**. The full model generates slightly greater predictive probabilities in comparison to the partial model. However, these probabilities do not surpass the 0.5 probability decision threshold.  

## Conclusion 

The aim of the project was to understand the predictive power of account attributes (following and following counts) and average sentiment of users on the hatefulness of a user towards the MeToo Movement. We ascertained average sentiment of tweets for every unique user and used this feature in a logistic regression model to predict the probability that a user is hateful towards the MeToo Movement. We then added 2 more features to the predictive logistic regression model: follower and following counts. In the secondary analysis, the same models were fit to data which included only user that have tweeted more than once about the MeToo Movement. All models generated accuracies above 70%; however, no models accurately predicted the hatefulness of a user. All models generated predictive probabilities of hateful users below 0.4. Together, results suggest that average sentiment, follower and following counts do not strongly predict hatefulness of a user.  

A limitation of the project was that we did not have username's of users and thus had to group users by following count, follower count, and location; meaning, we may have incorrectly categorized the same users as different users if any of the aforementioned variables changed over time. This may have made our prediction model less accurate. 

If I had more time, I would ask a different question of the data: how does sentiment of tweets change over time? Using the data from the secondary analysis (users who have tweeted more than once), I would have compared the sentiment of tweets chronologically, to see how this varied by user. This would allow us to understand how public opinion of the MeToo movement changed or didn’t change over time.  

## References  

Lindgren, S. (2019). Movement Mobilization in the Age of Hashtag Activism: Examining the Challenge of Noise, Hate, and Disengagement in the #MeToo Campaign. Policy & Internet, 11(4), 418–438. https://doi.org/10.1002/poi3.212 
```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```
## Appendix
```{r read in and expand data}
library(tidytext)
library(dplyr)
library(stringr)
library(textdata)
library(tidyverse)
library(caret)
library(ggplot2)
library(readr)

data2 <- read_csv("~/Library/CloudStorage/OneDrive-HarvardUniversity/MeTooHate.csv")
#######need to change to make it able to knit
data2$index <- 1:nrow(data2) 
set.seed(11+16+2022)
dat<-data2[sample(nrow(data2), 40000), ]

# grouping tweets by the user 'newid'
dat2 <- dat |> unite(newid, location, followers_count, friends_count, remove=FALSE)
dat2$newid <- as.factor(dat2$newid)

#removing links and stop words 
links <- "https://t.co/[A-Za-z\\d]+|&amp;"
dat3 <- dat2 |> filter(!is.na(text)) |>
  mutate(text = str_replace_all(text, links, "")) |>
  unnest_tokens(word, text, token = "tweets")
dat3 <- dat3 |> filter(!word %in% stop_words$word) 

```

```{r making average sentiment variable}
#getting average sentiment 
afinn<-get_sentiments("afinn")
summary<- dat3 |> inner_join(afinn, by = "word") |> 
  group_by(newid) |>
  summarize(avgsent=mean(value))

#joining back together for a table that has account characteristics and the average sentiment score grouped by user 
inner_join(summary, dat2, by= 'newid') |> nrow() #27661
senttable <- inner_join(summary, dat2, by= 'newid')

#remove columns not needed 
senttable <- senttable |>
  subset(select = -c(status_id, created_at, favorite_count, retweet_count,statuses_count))
```

```{r making a variable for proportion of hateful tweets}
senttable <- senttable |>
  group_by(newid) |>
  mutate(prop = mean(category)) 
```

```{r making variable for number of tweets}
senttable <- senttable |> 
  group_by(newid) |>
  mutate(ntweet=n())
```

```{r expoloratory part 1}
senttable |>
  group_by(newid) |>
  ggplot(aes(x=followers_count)) + 
  geom_histogram() +
  xlab('# of Followers') +
  labs(caption = 'Figure 1. The distribution of Followers by User') +
  theme(plot.caption=element_text(hjust = 0, face = "italic"))
  

senttable |>
 group_by(newid) |>
  ggplot(aes(x=friends_count)) + 
  geom_histogram() +
  xlab('# of Accounts Following') +
  labs(caption = 'Figure 2. The distribution of Accounts Following by User') +
  theme(plot.caption=element_text(hjust = 0, face = "italic"))
```

```{r remove outliers of following and followers}
followeriqr<- IQR(senttable$followers_count)
summary(senttable$followers_count)
504 + (1.5*followeriqr)
sum(senttable$followers_count>=4374)
sub <- senttable |>
  filter(followers_count<=4374) 

followingiqr<- IQR(senttable$friends_count)
summary(senttable$friends_count)
508 + (1.5*followingiqr)
sum(senttable$friends_count>=2846) 
sub <- sub |>
  filter(friends_count<=2846) 
```

```{r exploratory part 2}
cor.test(sub$followers_count, sub$friends_count) #0.5652156, p-value < 2.2e-16

#ADD SCATTERPLOT WITH LINE
sub |>
  group_by(newid) |>
  ggplot(aes(x=followers_count, y=friends_count)) + 
  geom_point()+
  geom_smooth(method = "lm") + 
  xlab("# of Followers") +
  ylab("# of Following") +
  labs(caption = 'Figure 3. Follower count versus following count per user') +
  theme(plot.caption=element_text(hjust = 0, face = "italic"))
``` 

```{r exploratory part 3}
sub |> 
  group_by(newid) |>
  ggplot(aes(followers_count, prop, size=ntweet)) +
  geom_point() +
  ylab('Proportion of Hateful Tweets') +
  xlab('# of Followers') + 
  labs(caption = 'Figure 4. The proportion of hateful tweets versus number of followers by user') +
  theme(plot.caption=element_text(hjust = 0, face = "italic"))

sub |> 
  group_by(newid) |>
  ggplot(aes(friends_count, prop, size=ntweet)) +
  geom_point() +
  ylab('Proportion of Hateful Tweets') +
  xlab('# of Accounts Following') + 
  labs(caption = 'Figure 5. The proportion of hateful tweets versus number of following count by user') +
  theme(plot.caption=element_text(hjust = 0, face = "italic"))
```

```{r making dichotomozed hateful user variable}
sub <- sub |> 
  group_by(newid) |>
  mutate(prop = mean(category == 1)) |>
  mutate(hateful=case_when(
    prop > 0 ~ 1,
    prop == 0 ~ 0
  )) 

sub$hateful <- as.factor(sub$hateful)

sub |>
  ggplot(aes(x=hateful, y=avgsent)) + 
  geom_boxplot() +
  xlab('Hateful User') +
  ylab('Avergae Sentiment of Tweets per User') +
  scale_x_discrete(labels=c("1" = "Yes", "0" = "No"))+
  labs(caption = 'Figure 6. Average aentiment among Hateful and nonhateful users') +
  theme(plot.caption=element_text(hjust = 0, face = "italic"))


logit1 <- glm(hateful ~ avgsent + followers_count, data=sub, family='binomial')
summary(logit1)
```

### Data Wrangling: Before & After
```{r showing the datasets}
head(data2,1) 
head(sub,1) 
```

```{r creating the train and test set}
dsub<- sub[!duplicated(sub$newid), ]
y <- as.factor(dsub$hateful)
test_index <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)

test_set <- dsub[test_index, ]
train_set <- dsub[-test_index, ]

nrow(train_set) # 14933
nrow(test_set) # 3735
```

```{r using average user sentiment to predict hateful accounte}
test_set$hateful <- as.factor(test_set$hateful)
train_set$hateful <- as.factor(train_set$hateful)
lm_fit <- mutate(train_set, y = hateful == 1)   
lm_fit2<- glm(y ~ avgsent, data = lm_fit, family='binomial') 

#PREDICTION RULE OF 0.5
p_hat <- predict(lm_fit2, test_set, type='response')
y_hat <- ifelse(p_hat > 0.5, '1', '0') |> as.factor()
hist(p_hat)
max(p_hat)
sd(p_hat)
confusionMatrix(y_hat, test_set$hateful)$overall[["Accuracy"]] #0.8353414
cm1all <- confusionMatrix(data=y_hat, reference = test_set$hateful)
cm1all
```

```{r confusion matrix plot for cm1 all ntweet counts}
Reference <- factor(c(0, 0, 1, 1))
Prediction <- factor(c(0, 1, 0, 1))
y <- c(3120, 0, 615, 0)
df <- data.frame(Reference, Prediction, y)

ggplot(data =  df, mapping = aes(x = Reference, y = Prediction)) +
  geom_tile(aes(fill = y), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", y)), vjust = 1) +
  scale_fill_gradient(low = "blue", high = "red") +
  theme_bw() + theme(legend.position = "none") +
  labs(caption = 'Figure 7. Actual hateful account vs. non-hateful account predictions using partial model') +
  theme(plot.caption=element_text(hjust = 0, face = "italic"))
  
```


```{r adding following and follower}
fit_glm <- glm(hateful ~ avgsent + followers_count+friends_count, data=train_set, family = "binomial")
p_hat_glm <- predict(fit_glm, test_set, type="response")
hist(p_hat_glm)
max(p_hat_glm)
sd(p_hat_glm)
y_hat_glm <- factor(ifelse(p_hat_glm > 0.5, '1', '0')) 
confusionMatrix(y_hat_glm, test_set$hateful)$overall["Accuracy"] #0.8353
cm2all <- confusionMatrix(data=y_hat_glm, reference = test_set$hateful)
cm2all
```

```{r confusion matrix plot for cm2 all ntweet counts}
Reference <- factor(c(0, 0, 1, 1))
Prediction <- factor(c(0, 1, 0, 1))
y <- c(3120, 0, 615, 0)
df <- data.frame(Reference, Prediction, y)

ggplot(data =  df, mapping = aes(x = Reference, y = Prediction)) +
  geom_tile(aes(fill = y), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", y)), vjust = 1) +
  scale_fill_gradient(low = "blue", high = "red") +
  theme_bw() + theme(legend.position = "none") +
  labs(caption = 'Figure 8. Actual hateful account vs. non-hateful account predictions using full model') +
  theme(plot.caption=element_text(hjust = 0, face = "italic"))
  
```

```{r how did probability change?}
str(p_hat)
str(p_hat_glm)
dfp_hat <- data.frame(p_hat)
dfp_hat_glm <- data.frame(p_hat_glm)

dfp_hat_glm <- dfp_hat_glm |>
  rename("p" = "p_hat_glm")

dfp_hat <- dfp_hat |>
  rename("p" = "p_hat")

dfp <- rbind(dfp_hat, dfp_hat_glm)


ggplot(dfp, aes(x= p)) + 
  geom_histogram(data = dfp_hat, fill = "red", alpha = 0.2) + 
  geom_histogram(data = dfp_hat_glm, fill = "blue", alpha = 0.4) +
  theme() + 
   labs(caption = 'Figure 9. Comparison of probability distributions for hateful account predicitons') + 
    theme(plot.caption=element_text(hjust = 0, face = "italic")) + scale_color_manual(name='Histogram',
                     breaks=c('Partial Model', 'Full Model', 'Overlayed'),
                     values=c('Overalyed'='purple', 'Full model'='blue', 'Partial Model'= 'red')) +
                       theme(legend.title=element_text(size=20), legend.text=element_text(size=14))
########ask why legend isnt working 
```

```{r how does it change when we only take those that have tweeted more than once?}
table(dsub$ntweet>=2,dsub$hateful==1)

sub2 <- sub |>
  filter(ntweet>=2)
nrow(sub2) 

dsub2<- sub2[!duplicated(sub2$newid), ]
nrow(dsub2)
y <- as.factor(dsub2$hateful)
test_index <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)

test_set <- dsub2[test_index, ]
train_set <- dsub2[-test_index, ]

class(dsub2$hateful)
test_set$hateful <- as.factor(test_set$hateful)
train_set$hateful <- as.factor(train_set$hateful)
lm_fit <- mutate(train_set, y = hateful == 1)   
lm_fit2<- lm(y ~ avgsent, data = lm_fit) 

#PREDICTION RULE OF 0.5
p_hat <- predict(lm_fit2, test_set)
hist(p_hat)
y_hat <- ifelse(p_hat > 0.5, '1', '0') |> as.factor()
confusionMatrix(y_hat, test_set$hateful)$overall[["Accuracy"]] #0.7273
cm1 <- confusionMatrix(data=y_hat, reference = test_set$hateful)
cm1

fit_glm <- glm(hateful ~ avgsent + followers_count+ friends_count, data=train_set, family = "binomial")
p_hat_glm <- predict(fit_glm, test_set, type="response")
hist(p_hat_glm)
y_hat_glm <- factor(ifelse(p_hat_glm > 0.5, '1', '0')) 
confusionMatrix(y_hat_glm, test_set$hateful)$overall["Accuracy"] #0.7272727 

cm2 <- confusionMatrix(data=y_hat_glm, reference = test_set$hateful)
cm2
```

```{r confusion matrices}
cm1
Reference <- factor(c(0, 0, 1, 1))
Prediction <- factor(c(0, 1, 0, 1))
y <- c(168, 0, 63, 0)
df <- data.frame(Reference, Prediction, y)

ggplot(data =  df, mapping = aes(x = Reference, y = Prediction)) +
  geom_tile(aes(fill = y), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", y)), vjust = 1) +
  scale_fill_gradient(low = "blue", high = "red") +
  theme_bw() + theme(legend.position = "none") +
  labs(caption = 'Figure 10. Actual hateful account vs. non-hateful account predictions among users with more than one tweet using partial model') +
  theme(plot.caption=element_text(hjust = 0, face = "italic"))

cm2 

ggplot(data =  df, mapping = aes(x = Reference, y = Prediction)) +
  geom_tile(aes(fill = y), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", y)), vjust = 1) +
  scale_fill_gradient(low = "blue", high = "red") +
  theme_bw() + theme(legend.position = "none") +
  labs(caption = 'Figure 11. Actual hateful account vs. non-hateful account predictions among users with more than one tweet using full model') +
  theme(plot.caption=element_text(hjust = 0, face = "italic"))
```

```{r how did probability change? part 2}
str(p_hat)
str(p_hat_glm)
dfp_hat <- data.frame(p_hat)
dfp_hat_glm <- data.frame(p_hat_glm)

dfp_hat_glm <- dfp_hat_glm |>
  rename("p" = "p_hat_glm")

dfp_hat <- dfp_hat |>
  rename("p" = "p_hat")

dfp <- rbind(dfp_hat, dfp_hat_glm)


ggplot(dfp, aes(x= p)) + 
  geom_histogram(data = dfp_hat, fill = "red", alpha = 0.2) + 
  geom_histogram(data = dfp_hat_glm, fill = "blue", alpha = 0.4) +
  theme() + 
   labs(caption = 'Figure 12. Comparison of probability distributions for hateful account predicitons using accounts with more than 1 tweet') + 
    theme(plot.caption=element_text(hjust = 0, face = "italic")) + scale_color_manual(name='Histogram',
                     breaks=c('Partial Model', 'Full Model', 'Overlayed'),
                     values=c('Overalyed'='purple', 'Full model'='blue', 'Partial Model'= 'red')) 
```
